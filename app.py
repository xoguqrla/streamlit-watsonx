import os
import logging
import streamlit as st
from dotenv import load_dotenv
from ibm_watsonx_ai import Credentials
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods

# ğŸ“Œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("API_KEY")
PROJECT_ID = os.getenv("PROJECT_ID")
API_URL = os.getenv("URL")

# ğŸ“Œ ë¡œê¹… ì„¤ì •
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(filename=f"{LOG_DIR}/chatbot.log", level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

st.set_page_config(page_title="Watsonx AI ì±—ë´‡", layout="wide")

# ğŸ¨ UI ìŠ¤íƒ€ì¼ ê°œì„ 
st.markdown(
    """
    <style>
    .stChatMessage { 
        border-radius: 10px;
        padding: 10px;
    }
    .stTextInput {
        border-radius: 5px;
    }
    .stWarning {
        color: orange;
    }
    .stSuccess {
        color: green;
    }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ¡ğŸ“±ğŸ’° Watsonx AI ì§€ì› ì •ë³´ ì±—ë´‡")

# ğŸ“Œ Watsonx LLM íŒŒë¼ë¯¸í„° ì„¤ì •
parameters = {
    GenParams.DECODING_METHOD: DecodingMethods.GREEDY.value,
    GenParams.MIN_NEW_TOKENS: 1,
    GenParams.MAX_NEW_TOKENS: 500,
    GenParams.STOP_SEQUENCES: ["<|endoftext|>"]
}

# ğŸ“Œ ëª¨ë¸ ìƒì„± í•¨ìˆ˜
@st.cache_resource
def create_llm():
    """IBM Watsonx AI ëª¨ë¸ ìƒì„±"""
    if not API_KEY or not PROJECT_ID or not API_URL:
        st.error("ğŸš¨ API í‚¤ ë˜ëŠ” í”„ë¡œì íŠ¸ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! `.env` íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    try:
        credentials = Credentials(url=API_URL, api_key=API_KEY)
        model = ModelInference(
            model_id="ibm/granite-3-8b-instruct",
            params=parameters,
            credentials=credentials,
            project_id=PROJECT_ID
        )
        return model
    except Exception as e:
        logging.error(f"âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        st.error("âŒ Watsonx ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return None

# ğŸ“Œ ëª¨ë¸ ë¡œë“œ
if "model" not in st.session_state:
    st.session_state.model = create_llm()

# ğŸ“Œ ì±„íŒ… ë©”ì‹œì§€ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = []

# ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ê°’ ì €ì¥ ê³µê°„
if "user_inputs" not in st.session_state:
    st.session_state.user_inputs = {"ì„±ë³„": None, "ë‚˜ì´": None, "ì¹´í…Œê³ ë¦¬": None, "ì§€ì—­": None}

# ğŸ“Œ Watsonx AI í˜¸ì¶œ í•¨ìˆ˜
def watsonx_ai_api(prompt):
    """Watsonx AIë¡œë¶€í„° ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if not prompt.strip():
        return "âš ï¸ ì…ë ¥ëœ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

    if st.session_state.model is None:
        return "âŒ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."

    try:
        response = st.session_state.model.generate(prompt=prompt)['results'][0]['generated_text'].strip()
        logging.info(f"ğŸ“¨ ì‚¬ìš©ì ì…ë ¥: {prompt}  | ğŸ“© ëª¨ë¸ ì‘ë‹µ: {response}")
        return response
    except Exception as e:
        logging.error(f"âŒ Watsonx ì‘ë‹µ ì˜¤ë¥˜: {str(e)}")
        return "ğŸš¨ Watsonx AIì™€ í†µì‹  ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# ğŸ“Œ ì„±ë³„ ì„ íƒ
st.sidebar.header("ğŸ”¹ ì„±ë³„ ì„ íƒ")
gender = st.sidebar.radio("ì„±ë³„ì„ ì„ íƒí•˜ì„¸ìš”:", ["ë‚¨ì", "ì—¬ì"])

# ğŸ“Œ ë‚˜ì´ ì„ íƒ
st.sidebar.header("ğŸ”¹ ë‚˜ì´ ì„ íƒ")
age = st.sidebar.selectbox("ë‚˜ì´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", list(range(10, 70, 5)))

# ğŸ“Œ ì¹´í…Œê³ ë¦¬ ì„ íƒ
st.sidebar.header("ğŸ”¹ ì¹´í…Œê³ ë¦¬ ì„ íƒ")
category = st.sidebar.selectbox("ê´€ì‹¬ ìˆëŠ” ì •ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ì£¼ê±°", "ì¼ìë¦¬", "ê¸ˆìœµ", "ë³´í—˜", "í•¸ë“œí°", "ì§€ì› ì œë„"])

# ğŸ“Œ ì§€ì—­ ì„ íƒ
st.sidebar.header("ğŸ”¹ ì§€ì—­ ì„ íƒ")
region = st.sidebar.text_input("ê±°ì£¼ ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì„œìš¸, ë¶€ì‚°, ëŒ€êµ¬)")

# ğŸ“Œ ì„ íƒ ì™„ë£Œ ë²„íŠ¼
if st.sidebar.button("âœ… ì„¤ì • ì™„ë£Œ"):
    if not region:
        st.sidebar.warning("ğŸš¨ ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš”!")
    else:
        st.session_state.user_inputs["ì„±ë³„"] = gender
        st.session_state.user_inputs["ë‚˜ì´"] = age
        st.session_state.user_inputs["ì¹´í…Œê³ ë¦¬"] = category
        st.session_state.user_inputs["ì§€ì—­"] = region
        st.sidebar.success(f"âœ… {region}ì— ê±°ì£¼í•˜ëŠ” {age}ì„¸ {gender}ë‹˜ì˜ {category} ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤!")

# ğŸ“Œ ê¸°ì¡´ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ğŸ“Œ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ì´ ìˆë‚˜ìš”?"):
    # ğŸ“Œ Watsonx í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
    user_info = f"ì‚¬ìš©ì ì •ë³´: {st.session_state.user_inputs['ì§€ì—­']} ê±°ì£¼ {st.session_state.user_inputs['ë‚˜ì´']}ì„¸ {st.session_state.user_inputs['ì„±ë³„']}."
    full_prompt = f"{user_info}\n\n{st.session_state.user_inputs['ì¹´í…Œê³ ë¦¬']} ê´€ë ¨ ì§ˆë¬¸ì…ë‹ˆë‹¤: {prompt}"

    st.session_state.messages.append({"role": "user", "content": full_prompt})

    with st.chat_message("user"):
        st.markdown(full_prompt)

    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– Watsonx AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘..."):
            response = watsonx_ai_api(full_prompt)
            # ğŸ“Œ ì‘ë‹µ ìµœì í™” (ì „í™”ë²ˆí˜¸, ì‚¬ì´íŠ¸ í¬í•¨)
            response += "\n\nğŸ“ ê´€ë ¨ ê¸°ê´€ ë¬¸ì˜: 123-456-7890\nğŸŒ ê³µì‹ í™ˆí˜ì´ì§€: www.example.com"
            st.write(response)

    st.session_state.messages.append({"role": "assistant", "content": response})
